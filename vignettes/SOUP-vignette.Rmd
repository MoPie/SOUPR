---
title: "A quick tour of SOUP"
author: "Lingxue Zhu"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A quick tour of SOUP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette walks through two data examples and illustrates the basic usage of `SOUP`.

## Installation
`SOUP` can be installed directly from GitHub with `devtools`: 
```{r, cache=TRUE}
#library(devtools)
#devtools::install_github("lingxuez/SOUP")
```

Now we can load `SOUP`. We also load the `ggplot2` package for visualization purpose.
```{r}
library(SOUP)
library(ggplot2)
```

## Fetal Brain Data
First, we illustrate the usage of SOUP on a fetal brain single-cell dataset (*Camp et al. (2015)*). The Camp data is distributed together with the SOUP package, with 220 cells and 12,694 genes, which can be loaded by
```{r}
## cell information, including reference cell types
cell.info = camp$cell.info
## cell-by-gene count matrix
counts = camp$counts
dim(counts)
```

To see more details of Camp data:
```{r, results="hide"}
help(camp)
```

### 1. Data pre-processing
In practice, we find it always beneficial to pre-process single-cell RNA-seq dataset, including:

1. Normalize such that each cell has total sum of $1e6$, which is equivalent to a TPM normalization.
2. Log transformation.

The following line performs these steps:
```{r}
log.expr = log2(scaleRowSums(counts)*(10^6) + 1)
```

### 2. Gene selection
```{r, cache=TRUE}
log.select.expr = log.expr[, colnames(log.expr) %in% camp$select.genes]
dim(log.expr)
```

### 3. SOUP clustering
SOUP clustering is then applied to the set of selected genes.  It is highly recommended to use the log-scaled data. We can run `SOUP` over a sequence of $K$'s, the number of clusters. The output includes a sequence of membership matrices, one per given $K$, as well as a sequence of cluster centers, one per given $K$.
```{r, cache=TRUE}
soup.out = SOUP(log.select.expr, Ks=c(2:5), type="log")
## Output includes a sequence of membership matrices
length(soup.out$memberships)
dim(soup.out$memberships[[1]])
## Output includes a sequence of cluster centers
length(soup.out$centers)
dim(soup.out$centers[[1]])
```

**Hard clustering.**
SOUP can be treated as hard clustering,  by assigning each cell to its major type with the largest membership. The hard assignments are stored in `soup.out$major.labels`:
```{r}
## one vector per given K
length(soup.out$major.labels)
## the results of K=5
table(soup.out$major.labels[[4]])
```

The function `heatmapKseq` provides a visualization of the hard clustering results of different $K$'s, compared to the reference cell type.
```{r, cache=TRUE, fig.width=7, fig.height=2.5}
g.kseq = heatmapKseq(memberships=soup.out$memberships, 
                     Ks=soup.out$Ks, 
                     cell.type=cell.info$cell.type)
g.kseq
```

**Soft membership and trajectory.**
On the other hand, using SOUP soft memberships, one can obtain an ordering of cells corresponding to their developmental trajectory. In particular, we estimate a timepoint for each cell by

1. Order the clusters so that they represent developmental order. In this dataset, we first identify the ending point by using the cluster with the largest group of `N3` cells, which is the group of most matured neurons. Then we consecutively find the next previous cluster that has the highest cluster center correlation.

2. The timepoint of cell i is estimated by $t_i = \sum_k k \hat{\theta}_{ik}$, where $\hat{\theta}_{i \cdot}$ is the estimated SOUP membership.

The function `getTimeline` implements these steps, and returns the vector $(t_1, ..., t_n)$. Here, we present the results with $K=5$:
```{r, cache=TRUE}
## use K=5
K.use = 5
i.K = match(K.use, soup.out$Ks)
## pick the ending point: with the most N3 cells
soup.label = soup.out$major.labels[[i.K]]
k.end = which.max(table(soup.label, cell.info$cell.type)[, "N3"])
## estimate timepoints
soup.timeline = getTimeline(membership = soup.out$memberships[[i.K]],
                            centers = soup.out$centers[[i.K]],
                            k.end=k.end)
```

To examine the estimated trajectory, we visualize the expression levels of 5 marker genes along the estimated SOUP trajectory, using function `plotMultipleGeneTimeline`:
```{r, cache=TRUE, fig.width=7, fig.height=3.5}
## visualize timeline
genelist = c("CCNB1", "PAX6", "SOX2", "NEUROD6", "MEF2C")
g.timeline = plotMultipleGeneTimeline(expr=log.expr, 
                                      genelist=genelist,
                                      timeline=soup.timeline, 
                                      nrow=2, ncol=3)
g.timeline
```


### 4. Cross Validation
Finally, we present a cross validation procedure to select the optimal $K$, number of clusters. In particular, we search over $K\in\{2, .., 10}$ using 10-fold cross validation, and the errors are averaged over `nCV` repetitions. For illustration purpose, here we conduct only 2 repetitions. A parallelization option has been implemented, and the number of cores to be used can be specified via `mc.cores`. Note that the computation is parallelized across folds, so there is no need to use more than `nfold` of cores. For reproducibility, we set the seeds below:
```{r, cache=TRUE}
Ks=c(2:10)
system.time({
  cv.soup.out = cvSOUP(log.expr, Ks=Ks, type="log",
                       nfold=10, nCV=2, mc.cores = 2,
                       seeds=c(42, 142))
})
```

The optimal $K$ is the one that achieves the lowest cross validation error, given by `cv.soup.out$K.cv`. We visualize the cross validation error, in the log scale, over different $K$'s. For better visualization, values are capped at 2.5:
```{r}
trunc.log.cvm = pmin(log(cv.soup.out$cvm), 2.5)
plot(Ks, trunc.log.cvm)
abline(v=cv.soup.out$K.cv, lty=4, lwd=2, col="darkblue",
       xlab="K", ylab="cross validation error")
```


